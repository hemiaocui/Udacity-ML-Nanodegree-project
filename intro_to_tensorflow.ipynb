{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TensorFlow Neural Network Lab</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this lab, you'll use all the tools you learned from *Introduction to TensorFlow* to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in different fonts.\n",
    "\n",
    "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. Your goal, by the end of this lab, is to make predictions against that test set with at least an 80% accuracy. Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 210001/210001 [00:45<00:00, 4654.03files/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 10001/10001 [00:02<00:00, 4641.62files/s]\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')#tqdm displays progress bar. \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            #print (filename)\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    #print (image_file)\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Mean Variance - Image.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for your training and test data.\n",
    "\n",
    "Implement Min-Max scaling in the `normalize_grayscale()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
    "\n",
    "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$\n",
    "\n",
    "*If you're having trouble solving problem 1, you can view the solution [here](https://github.com/udacity/deep-learning/blob/master/intro-to-tensorFlow/intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Min-Max scaling for grayscale image dat\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal: #feature has not been normalized yet. \n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['J', 'H', 'D', ..., 'C', 'C', 'I'], dtype='<U1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.11568628, 0.23490196, 0.35411766, 0.46078432,\n",
       "       0.5862745 , 0.70549023, 0.7619608 , 0.8152942 , 0.8905883 ,\n",
       "       0.8717647 , 0.90000004, 0.38235295, 0.1       , 0.11254902,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.14078432, 0.49215686,\n",
       "       0.8027451 , 0.7839216 , 0.72431374, 0.66470593, 0.542353  ,\n",
       "       0.68980396, 0.90000004, 0.8905883 , 0.874902  , 0.90000004,\n",
       "       0.3854902 , 0.1       , 0.11254902, 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.14705883, 0.24745098, 0.14078432, 0.1       ,\n",
       "       0.10313725, 0.11568628, 0.1       , 0.4482353 , 0.90000004,\n",
       "       0.8780393 , 0.874902  , 0.90000004, 0.3854902 , 0.1       ,\n",
       "       0.11254902, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.10313725, 0.12509803,\n",
       "       0.1       , 0.4576471 , 0.90000004, 0.8780393 , 0.874902  ,\n",
       "       0.90000004, 0.3854902 , 0.1       , 0.11254902, 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.10627451, 0.10313725,\n",
       "       0.10313725, 0.1       , 0.11568628, 0.1       , 0.45137253,\n",
       "       0.90000004, 0.8780393 , 0.874902  , 0.90000004, 0.3854902 ,\n",
       "       0.1       , 0.11254902, 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.11568628, 0.1       , 0.45137253, 0.90000004, 0.8780393 ,\n",
       "       0.874902  , 0.90000004, 0.3854902 , 0.1       , 0.11254902,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.11568628, 0.1       ,\n",
       "       0.45137253, 0.90000004, 0.8780393 , 0.874902  , 0.90000004,\n",
       "       0.3854902 , 0.1       , 0.11254902, 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.11568628, 0.1       , 0.45137253, 0.90000004,\n",
       "       0.8780393 , 0.874902  , 0.90000004, 0.3854902 , 0.1       ,\n",
       "       0.11254902, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.10313725, 0.11254902, 0.11254902, 0.11254902, 0.1282353 ,\n",
       "       0.1       , 0.4576471 , 0.90000004, 0.8780393 , 0.8780393 ,\n",
       "       0.90000004, 0.39490196, 0.1       , 0.12509803, 0.11254902,\n",
       "       0.11254902, 0.10627451, 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.11568628, 0.1       , 0.44509804,\n",
       "       0.90000004, 0.8686275 , 0.8686275 , 0.90000004, 0.38235295,\n",
       "       0.1       , 0.11254902, 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.10313725,\n",
       "       0.1       , 0.1627451 , 0.44509804, 0.42313725, 0.42941177,\n",
       "       0.43254903, 0.4043137 , 0.66784316, 0.90000004, 0.887451  ,\n",
       "       0.887451  , 0.90000004, 0.6176471 , 0.39803922, 0.43568626,\n",
       "       0.42313725, 0.45137253, 0.21294118, 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.10627451, 0.10941177,\n",
       "       0.10941177, 0.10941177, 0.11254902, 0.1       , 0.22862744,\n",
       "       0.7650981 , 0.72431374, 0.7368628 , 0.73372555, 0.74627453,\n",
       "       0.7211765 , 0.68352944, 0.68980396, 0.6929412 , 0.68352944,\n",
       "       0.72431374, 0.7431373 , 0.7368628 , 0.72431374, 0.7776471 ,\n",
       "       0.32588238, 0.1       , 0.10627451, 0.10941177, 0.10941177,\n",
       "       0.10627451, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.64274514,\n",
       "       0.714902  , 0.714902  , 0.714902  , 0.714902  , 0.714902  ,\n",
       "       0.7180393 , 0.72431374, 0.72431374, 0.72431374, 0.727451  ,\n",
       "       0.73058826, 0.73058826, 0.7368628 , 0.7368628 , 0.73372555,\n",
       "       0.73372555, 0.73058826, 0.727451  , 0.72431374, 0.72431374,\n",
       "       0.72431374, 0.7180393 , 0.714902  , 0.714902  , 0.714902  ,\n",
       "       0.714902  , 0.62392163, 0.4043137 , 0.44509804, 0.44509804,\n",
       "       0.44509804, 0.44509804, 0.4482353 , 0.45137253, 0.4576471 ,\n",
       "       0.4576471 , 0.45137253, 0.43254903, 0.4137255 , 0.39803922,\n",
       "       0.38235295, 0.3792157 , 0.3917647 , 0.4043137 , 0.41686276,\n",
       "       0.43254903, 0.45137253, 0.4576471 , 0.45137253, 0.4482353 ,\n",
       "       0.44509804, 0.44509804, 0.44509804, 0.44509804, 0.39490196,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.10627451, 0.17529413, 0.2882353 , 0.39803922, 0.4262745 ,\n",
       "       0.34470588, 0.2537255 , 0.1627451 , 0.10627451, 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.11254902, 0.11254902,\n",
       "       0.11254902, 0.11254902, 0.1       , 0.10313725, 0.20666668,\n",
       "       0.40117648, 0.58000004, 0.7619608 , 0.874902  , 0.85607845,\n",
       "       0.74627453, 0.702353  , 0.7776471 , 0.874902  , 0.90000004,\n",
       "       0.90000004, 0.8309805 , 0.70862746, 0.53294116, 0.27882355,\n",
       "       0.10941177, 0.10627451, 0.11254902, 0.11254902, 0.11254902,\n",
       "       0.10941177, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.20352942, 0.6364706 , 0.85921574, 0.90000004, 0.90000004,\n",
       "       0.71176475, 0.35411766, 0.17215687, 0.10313725, 0.10313725,\n",
       "       0.1       , 0.14392157, 0.2882353 , 0.60196084, 0.8717647 ,\n",
       "       0.90000004, 0.8905883 , 0.8937256 , 0.592549  , 0.14078432,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.10313725, 0.1       , 0.1627451 , 0.8121569 , 0.90000004,\n",
       "       0.887451  , 0.90000004, 0.7494118 , 0.1909804 , 0.1       ,\n",
       "       0.10627451, 0.10313725, 0.11254902, 0.11568628, 0.10313725,\n",
       "       0.11882353, 0.1       , 0.54862744, 0.90000004, 0.8780393 ,\n",
       "       0.8780393 , 0.90000004, 0.22862744, 0.1       , 0.10313725,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.14078432, 0.67098045, 0.90000004, 0.8905883 , 0.90000004,\n",
       "       0.90000004, 0.7494118 , 0.4545098 , 0.25058824, 0.1282353 ,\n",
       "       0.1       , 0.10313725, 0.10941177, 0.1       , 0.21294118,\n",
       "       0.7494118 , 0.90000004, 0.8905883 , 0.85607845, 0.44196078,\n",
       "       0.11254902, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.12196079,\n",
       "       0.41058823, 0.6992157 , 0.8498039 , 0.90000004, 0.89686275,\n",
       "       0.90000004, 0.8811765 , 0.79647064, 0.6772549 , 0.53607845,\n",
       "       0.44509804, 0.5894118 , 0.862353  , 0.8278432 , 0.6113726 ,\n",
       "       0.3854902 , 0.1627451 , 0.1       , 0.10313725, 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.10627451, 0.1       , 0.1       , 0.1       ,\n",
       "       0.15960784, 0.3917647 , 0.6992157 , 0.90000004, 0.8937256 ,\n",
       "       0.90000004, 0.90000004, 0.90000004, 0.90000004, 0.89686275,\n",
       "       0.90000004, 0.77137256, 0.53607845, 0.3290196 , 0.15333334,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.11882353, 0.33215687, 0.53294116, 0.7180393 , 0.84666675,\n",
       "       0.8184314 , 0.64901966, 0.4482353 , 0.27568626, 0.26      ,\n",
       "       0.40117648, 0.5611765 , 0.74      , 0.8780393 , 0.90000004,\n",
       "       0.89686275, 0.90000004, 0.84352946, 0.6113726 , 0.18470588,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.34156865, 0.77450985, 0.90000004,\n",
       "       0.90000004, 0.8811765 , 0.58000004, 0.18784314, 0.1       ,\n",
       "       0.10627451, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.11882353, 0.23490196, 0.5737255 , 0.85921574, 0.90000004,\n",
       "       0.8937256 , 0.90000004, 0.7619608 , 0.1564706 , 0.1       ,\n",
       "       0.10313725, 0.1       , 0.1       , 0.1       , 0.15960784,\n",
       "       0.90000004, 0.8905883 , 0.8780393 , 0.90000004, 0.714902  ,\n",
       "       0.1       , 0.11568628, 0.10627451, 0.12509803, 0.12196079,\n",
       "       0.11882353, 0.11882353, 0.12509803, 0.10941177, 0.11254902,\n",
       "       0.1       , 0.6992157 , 0.90000004, 0.874902  , 0.8937256 ,\n",
       "       0.85921574, 0.17215687, 0.1       , 0.10313725, 0.1       ,\n",
       "       0.1       , 0.1       , 0.11568628, 0.542353  , 0.90000004,\n",
       "       0.8905883 , 0.90000004, 0.8811765 , 0.60823536, 0.23803923,\n",
       "       0.1       , 0.10313725, 0.1       , 0.1       , 0.1       ,\n",
       "       0.10313725, 0.1       , 0.15019608, 0.542353  , 0.8780393 ,\n",
       "       0.90000004, 0.90000004, 0.79647064, 0.29450983, 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.10627451, 0.2882353 , 0.5831373 , 0.7776471 ,\n",
       "       0.874902  , 0.90000004, 0.8937256 , 0.79960793, 0.62078434,\n",
       "       0.48901963, 0.38235295, 0.34156865, 0.46078432, 0.6584314 ,\n",
       "       0.85607845, 0.90000004, 0.8403922 , 0.6772549 , 0.4137255 ,\n",
       "       0.1345098 , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       , 0.10627451,\n",
       "       0.1       , 0.1       , 0.12196079, 0.25686276, 0.3854902 ,\n",
       "       0.53294116, 0.66784316, 0.7494118 , 0.8152942 , 0.84352946,\n",
       "       0.8152942 , 0.7682353 , 0.6803922 , 0.51411766, 0.33529413,\n",
       "       0.17843138, 0.10313725, 0.1       , 0.1       , 0.10627451,\n",
       "       0.1       , 0.1       , 0.1       , 0.1       ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer() #more dense than one-hot encoding. \n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    train_features = pickle_data['train_dataset']\n",
    "    train_labels = pickle_data['train_labels']\n",
    "    valid_features = pickle_data['valid_dataset']\n",
    "    valid_labels = pickle_data['valid_labels']\n",
    "    test_features = pickle_data['test_dataset']\n",
    "    test_labels = pickle_data['test_labels']\n",
    "    del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below problems uses batch gradient descent to update parameters though it is relatively slow as compared to using backward proporgation, which is typical in neural network. \n",
    "\n",
    "### Here, there is not even a hidden layer. as we just direcly convert XW to y using softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2\n",
    "\n",
    "Now it's time to build a simple neural network using TensorFlow. Here, your network will be just an input layer and an output layer.\n",
    "\n",
    "<img src=\"image/network_diagram.png\" style=\"height: 40%;width: 40%; position: relative; right: 10%\">\n",
    "\n",
    "For the input here the images have been flattened into a vector of $28 \\times 28 = 784$ features. Then, we're trying to predict the image digit so there are 10 output units, one for each label. Of course, feel free to add hidden layers if you want, but this notebook is built to guide you through a single layer network. \n",
    "\n",
    "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
    " - `features`\n",
    "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
    " - `labels`\n",
    "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
    " - `weights`\n",
    "  - Variable Tensor with random numbers from a truncated normal distribution.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
    " - `biases`\n",
    "  - Variable Tensor with all zeros.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help.\n",
    "\n",
    "*If you're having trouble solving problem 2, review \"TensorFlow Linear Function\" section of the class.  If that doesn't help, the solution for this problem is available [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# All the pixels in the image (28 * 28 = 784)\n",
    "features_count = 784\n",
    "# All the labels\n",
    "labels_count = 10\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "features = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# TODO: Set the weights and biases tensors\n",
    "weights = tf.Variable(tf.truncated_normal((features_count, labels_count), mean=0.0, stddev=1.0, dtype=tf.float32, seed=1))\n",
    "biases = tf.Variable(tf.zeros(labels_count))\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "\n",
    "#Test Cases\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
    "assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
    "assert isinstance(weights, Variable), 'weights must be a TensorFlow variable'\n",
    "assert isinstance(biases, Variable), 'biases must be a TensorFlow variable'\n",
    "\n",
    "assert features._shape == None or (\\ #feature shape should be either none or none,784. ow, return incorrect\n",
    "    features._shape.dims[0].value is None and\\\n",
    "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
    "assert labels._shape  == None or (\\\n",
    "    labels._shape.dims[0].value is None and\\\n",
    "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
    "assert weights._variable._shape == (784, 10), 'The shape of weights is incorrect'\n",
    "assert biases._variable._shape == (10), 'The shape of biases is incorrect' #this means 10X1 shape. \n",
    "\n",
    "assert features._dtype == tf.float32, 'features must be type float32'\n",
    "assert labels._dtype == tf.float32, 'labels must be type float32'\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases #n casesX 784 *784X10=n casesX10\n",
    "\n",
    "prediction = tf.nn.softmax(logits) #A SOFTMAX layer generalizes SIGMOID to when there are more than two classes. \n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1) #sum across features\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy) #average across cases. \n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Test Cases\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(loss, feed_dict=train_feed_dict)\n",
    "    session.run(loss, feed_dict=valid_feed_dict)\n",
    "    session.run(loss, feed_dict=test_feed_dict)\n",
    "    biases_data = session.run(biases)\n",
    "\n",
    "assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an explanaton on tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = tf.convert_to_tensor(np.array([[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]]))\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(y_hat)\n",
    "# array([[ 0.5,  1.5,  0.1],\n",
    "#        [ 2.2,  1.3,  1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "reduce_mean: Computes the mean of elements across dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_softmax = tf.nn.softmax(y_hat)\n",
    "y_true = tf.convert_to_tensor(np.array([[0.0, 1.0, 0.0],[0.0, 0.0, 1.0]])) \n",
    "loss_per_instance_1 = -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=1)\n",
    "with tf.Session() as sess:\n",
    "    y_hat_softmax=sess.run(y_hat_softmax)\n",
    "    y_true=sess.run(y_true)\n",
    "    loss_per_instance_1=sess.run(loss_per_instance_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.227863  , 0.61939586, 0.15274114],\n",
       "       [0.49674623, 0.20196195, 0.30129182]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4790107 , -0.4790107 , -1.8790107 ],\n",
       "       [-0.69967598, -1.59967598, -1.19967598]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(y_hat_softmax) #log with base e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4790107 , 1.19967598])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_per_instance_1# loss for each cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below continue with the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1)) #use max because \n",
    "#max refers to the one has highest probability or label. \n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32)) #cast it to the new dtype\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Learn Rate Tune - Image.png\" style=\"height: 70%;width: 70%\">\n",
    "## Problem 3\n",
    "Below are 2 parameter configurations for training the neural network. In each configuration, one of the parameters has multiple options. For each configuration, choose the option that gives the best acccuracy.\n",
    "\n",
    "Parameter configurations:\n",
    "\n",
    "Configuration 1\n",
    "* **Epochs:** 1\n",
    "* **Learning Rate:**\n",
    "  * 0.8\n",
    "  * 0.5\n",
    "  * 0.1\n",
    "  * 0.05\n",
    "  * 0.01\n",
    "\n",
    "Configuration 2\n",
    "* **Epochs:**\n",
    "  * 1\n",
    "  * 2\n",
    "  * 3\n",
    "  * 4\n",
    "  * 5\n",
    "* **Learning Rate:** 0.2\n",
    "\n",
    "The code will print out a Loss and Accuracy graph, so you can see how well the neural network performed.\n",
    "\n",
    "*If you're having trouble solving problem 3, you can view the solution [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   0%|                                                                        | 0/1114 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   0%|                                                                | 1/1114 [00:00<08:25,  2.20batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   2%|█▏                                                             | 22/1114 [00:00<05:49,  3.13batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   4%|██▋                                                            | 48/1114 [00:00<03:59,  4.44batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   5%|███▍                                                           | 60/1114 [00:01<02:58,  5.89batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   8%|████▉                                                          | 87/1114 [00:01<02:03,  8.33batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   9%|█████▋                                                        | 102/1114 [00:01<01:35, 10.61batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  11%|██████▌                                                       | 119/1114 [00:01<01:07, 14.76batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  13%|████████▏                                                     | 146/1114 [00:01<00:47, 20.58batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  15%|█████████                                                     | 163/1114 [00:02<00:40, 23.59batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  17%|██████████▍                                                   | 187/1114 [00:02<00:28, 32.28batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  18%|███████████▎                                                  | 203/1114 [00:03<00:27, 33.05batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  21%|████████████▋                                                 | 229/1114 [00:03<00:19, 44.68batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  23%|█████████████▉                                                | 251/1114 [00:03<00:19, 44.87batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  25%|███████████████▏                                              | 274/1114 [00:03<00:14, 58.98batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  27%|████████████████▊                                             | 301/1114 [00:04<00:14, 57.57batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  29%|██████████████████                                            | 324/1114 [00:04<00:10, 74.00batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  32%|███████████████████▌                                          | 351/1114 [00:04<00:11, 66.88batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  34%|████████████████████▊                                         | 375/1114 [00:04<00:08, 85.00batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  35%|█████████████████████▌                                       | 394/1114 [00:05<00:07, 101.26batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  37%|██████████████████████▊                                       | 411/1114 [00:05<00:13, 54.02batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  39%|███████████████████████▉                                      | 429/1114 [00:05<00:10, 68.21batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  40%|█████████████████████████                                     | 451/1114 [00:06<00:11, 56.49batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  42%|██████████████████████████▎                                   | 472/1114 [00:06<00:08, 72.28batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  45%|███████████████████████████▋                                  | 497/1114 [00:06<00:06, 91.48batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  46%|████████████████████████████▌                                 | 514/1114 [00:07<00:10, 58.08batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  48%|██████████████████████████████                                | 540/1114 [00:07<00:07, 75.46batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  50%|███████████████████████████████                               | 557/1114 [00:07<00:10, 52.78batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  52%|████████████████████████████████                              | 577/1114 [00:07<00:07, 67.52batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  54%|█████████████████████████████████▏                            | 597/1114 [00:07<00:06, 84.11batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  55%|██████████████████████████████████▏                           | 614/1114 [00:08<00:08, 58.60batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  56%|██████████████████████████████████▉                           | 628/1114 [00:08<00:06, 70.57batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  58%|████████████████████████████████████                          | 649/1114 [00:08<00:05, 87.69batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  60%|████████████████████████████████████▉                         | 664/1114 [00:09<00:08, 54.97batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  62%|██████████████████████████████████████▍                       | 691/1114 [00:09<00:05, 72.01batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  63%|███████████████████████████████████████▎                      | 707/1114 [00:09<00:07, 53.74batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  65%|████████████████████████████████████████▌                     | 729/1114 [00:09<00:05, 69.33batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  67%|█████████████████████████████████████████▊                    | 751/1114 [00:10<00:05, 62.06batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  70%|███████████████████████████████████████████▏                  | 775/1114 [00:10<00:04, 78.88batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  71%|████████████████████████████████████████████                  | 791/1114 [00:10<00:03, 91.14batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  72%|████████████████████████████████████████████▊                 | 806/1114 [00:10<00:05, 58.39batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  74%|██████████████████████████████████████████████                | 827/1114 [00:11<00:03, 74.40batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  76%|███████████████████████████████████████████████▎              | 851/1114 [00:11<00:04, 64.52batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  78%|████████████████████████████████████████████████▋             | 874/1114 [00:11<00:02, 81.94batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  80%|█████████████████████████████████████████████████▍            | 889/1114 [00:11<00:02, 92.09batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  81%|██████████████████████████████████████████████████▎           | 904/1114 [00:12<00:03, 55.52batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  83%|███████████████████████████████████████████████████▎          | 923/1114 [00:12<00:02, 70.19batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  85%|████████████████████████████████████████████████████▌         | 945/1114 [00:12<00:01, 87.80batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  86%|█████████████████████████████████████████████████████▍        | 961/1114 [00:13<00:02, 54.72batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  88%|██████████████████████████████████████████████████████▍       | 977/1114 [00:13<00:02, 67.85batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  90%|██████████████████████████████████████████████████████▊      | 1001/1114 [00:13<00:01, 61.65batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  92%|████████████████████████████████████████████████████████▏    | 1025/1114 [00:13<00:01, 79.06batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  94%|█████████████████████████████████████████████████████████▌   | 1051/1114 [00:14<00:00, 69.13batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  96%|██████████████████████████████████████████████████████████▊  | 1075/1114 [00:14<00:00, 87.53batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:  98%|███████████████████████████████████████████████████████████ | 1096/1114 [00:14<00:00, 105.48batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1: 100%|████████████████████████████████████████████████████████████▉| 1113/1114 [00:15<00:00, 54.29batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1: 100%|█████████████████████████████████████████████████████████████| 1114/1114 [00:15<00:00, 73.85batches/s]"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size)) #mini batch gradient descent;\n",
    "#len(train_features) refers m, number of cases\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar: #each loop refers to process one batch: 128 cases. \n",
    "            # Get a batch of training features and labels\n",
    "            print (batch_i) \n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "  \n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "#model is fit using batch feature and batch label. \n",
    "\n",
    "            # Log every 50 batches #this means we caculate accuacry every 50 batches. \n",
    "            if not batch_i % log_batch_step:#batch_i=1 means first 128 cases or first batch. \n",
    "                #only not 50 % 50 returns true. thus, it records accucary at \n",
    "                #50th batch, 100th batch etc. \n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict) #\n",
    "                #train_feed_dict = {features: train_features, labels: train_labels}\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "                # accurary is calculated using entire training set and valiation set. \n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0 #0 on first run.\n",
    "                batches.append(log_batch_step + previous_batch) #on first run, returns 50; \n",
    "                loss_batch.append(l) #l is the the loss \n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "        test_accuracy1 = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not 2 % 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not 50 % 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch  1/1: 100%|█████████████████████████████████████████████████████████████| 1114/1114 [09:04<00:00,  2.05batches/s]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_pbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.334848,\n",
       " 5.0812974,\n",
       " 3.7063599,\n",
       " 2.9149628,\n",
       " 2.4387293,\n",
       " 2.5613048,\n",
       " 2.381213,\n",
       " 2.4304428,\n",
       " 2.5162287,\n",
       " 2.710338,\n",
       " 2.2096157,\n",
       " 1.4620798,\n",
       " 2.0020761,\n",
       " 1.6064056,\n",
       " 1.5734966,\n",
       " 2.007847,\n",
       " 1.5616083,\n",
       " 1.20643,\n",
       " 1.5028458,\n",
       " 1.860614,\n",
       " 1.402494,\n",
       " 1.6033642,\n",
       " 2.0439355]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11782456,\n",
       " 0.3703649,\n",
       " 0.48650527,\n",
       " 0.57509476,\n",
       " 0.62037194,\n",
       " 0.6378105,\n",
       " 0.6597684,\n",
       " 0.6749824,\n",
       " 0.6811789,\n",
       " 0.69658244,\n",
       " 0.70193684,\n",
       " 0.70685613,\n",
       " 0.7096702,\n",
       " 0.72074383,\n",
       " 0.7206947,\n",
       " 0.72597194,\n",
       " 0.72654736,\n",
       " 0.7309965,\n",
       " 0.732814,\n",
       " 0.7373965,\n",
       " 0.739207,\n",
       " 0.73933333,\n",
       " 0.74145967]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.7400000095367432\n"
     ]
    }
   ],
   "source": [
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world.  You should have a test accuracy of at least 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can run above or we can just add one line to code :\n",
    "test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "to above as what I did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   0%|                                                                        | 0/1114 [00:00<?, ?batches/s]\n",
      "Epoch  1/1:   5%|███▍                                                          | 61/1114 [00:00<00:01, 531.60batches/s]\n",
      "Epoch  1/1:  10%|██████                                                       | 110/1114 [00:00<00:01, 517.28batches/s]\n",
      "Epoch  1/1:  14%|████████▎                                                    | 151/1114 [00:00<00:02, 477.23batches/s]\n",
      "Epoch  1/1:  17%|██████████▌                                                  | 194/1114 [00:00<00:01, 460.05batches/s]\n",
      "Epoch  1/1:  23%|█████████████▉                                               | 254/1114 [00:00<00:01, 489.82batches/s]\n",
      "Epoch  1/1:  27%|████████████████▎                                            | 299/1114 [00:00<00:01, 460.23batches/s]\n",
      "Epoch  1/1:  31%|██████████████████▌                                          | 340/1114 [00:00<00:01, 433.40batches/s]\n",
      "Epoch  1/1:  34%|████████████████████▊                                        | 381/1114 [00:00<00:01, 412.23batches/s]\n",
      "Epoch  1/1:  38%|███████████████████████▏                                     | 424/1114 [00:00<00:01, 403.35batches/s]\n",
      "Epoch  1/1:  43%|██████████████████████████▍                                  | 483/1114 [00:01<00:01, 438.10batches/s]\n",
      "Epoch  1/1:  48%|█████████████████████████████▏                               | 532/1114 [00:01<00:01, 448.83batches/s]\n",
      "Epoch  1/1:  52%|███████████████████████████████▌                             | 577/1114 [00:01<00:01, 406.26batches/s]\n",
      "Epoch  1/1:  56%|██████████████████████████████████▍                          | 629/1114 [00:01<00:01, 425.21batches/s]\n",
      "Epoch  1/1:  60%|████████████████████████████████████▊                        | 673/1114 [00:01<00:01, 415.40batches/s]\n",
      "Epoch  1/1:  67%|████████████████████████████████████████▋                    | 743/1114 [00:01<00:00, 461.13batches/s]\n",
      "Epoch  1/1:  72%|███████████████████████████████████████████▉                 | 803/1114 [00:01<00:00, 490.57batches/s]\n",
      "Epoch  1/1:  78%|███████████████████████████████████████████████▎             | 864/1114 [00:01<00:00, 513.70batches/s]\n",
      "Epoch  1/1:  83%|██████████████████████████████████████████████████▊          | 928/1114 [00:01<00:00, 538.17batches/s]\n",
      "Epoch  1/1:  88%|█████████████████████████████████████████████████████▉       | 984/1114 [00:02<00:00, 540.78batches/s]\n",
      "Epoch  1/1:  93%|████████████████████████████████████████████████████████    | 1040/1114 [00:02<00:00, 511.49batches/s]\n",
      "Epoch  1/1:  98%|██████████████████████████████████████████████████████████▊ | 1093/1114 [00:02<00:00, 511.06batches/s]\n",
      "Epoch  1/1: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:02<00:00, 477.58batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice Job! Test Accuracy is 0.8145999908447266\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "\n",
    "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layers\n",
    "Good job!  You built a one layer TensorFlow network!  However, you might want to build more than one layer.  This is deep learning after all!  In the next section, you will start to satisfy your need for more layers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
